{
  "origin": "codeshovel",
  "repositoryName": "elasticsearch",
  "repositoryPath": "/home/ncbradley/codeshovel-repos/elasticsearch/.git",
  "startCommitName": "7c0fc209bf78e4824ca1f232b84a1dab22bc2dfa",
  "sourceFileName": "BlendedTermQuery.java",
  "functionName": "blend",
  "functionId": "blend___contexts-TermContext[]__maxDoc-int__reader-IndexReader",
  "sourceFilePath": "server/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java",
  "functionStartLine": 101,
  "functionEndLine": 184,
  "changeHistory": [
    "99f88f15c5febbca2d13b5b5fda27b844153bf1a",
    "c8496fc4f44735962646c1f02572443bf57d3018",
    "ff4a11aa32b43a1109a364b5d4fed4f8310d0f6c",
    "15a62448343fd24f8e63f43b1e4b16f50005e4a5",
    "fd416d5ed5d0487964ce13d472fb2f31d456ca3b",
    "162ca993762ffb5f720ae7f82adcc209d16a5bd2"
  ],
  "changeHistoryShort": {
    "99f88f15c5febbca2d13b5b5fda27b844153bf1a": "Yfilerename",
    "c8496fc4f44735962646c1f02572443bf57d3018": "Ybodychange",
    "ff4a11aa32b43a1109a364b5d4fed4f8310d0f6c": "Ybodychange",
    "15a62448343fd24f8e63f43b1e4b16f50005e4a5": "Yfilerename",
    "fd416d5ed5d0487964ce13d472fb2f31d456ca3b": "Ybodychange",
    "162ca993762ffb5f720ae7f82adcc209d16a5bd2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "99f88f15c5febbca2d13b5b5fda27b844153bf1a": {
      "type": "Yfilerename",
      "commitMessage": "Rename core module to server (#28180)\n\nThis is related to #27933. It renames the core module to server. This is\r\nthe first step towards introducing an elasticsearch-core jar.",
      "commitDate": 1515695443000,
      "commitName": "99f88f15c5febbca2d13b5b5fda27b844153bf1a",
      "commitAuthor": "Tim Brooks",
      "commitDateOld": 1515688270000,
      "commitNameOld": "7d0eb3292b8f8ba27ef50dbbf38783dc68c70728",
      "commitAuthorOld": "Martijn van Groningen",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": ""
    },
    "c8496fc4f44735962646c1f02572443bf57d3018": {
      "type": "Ybodychange",
      "commitMessage": "Upgrade to Lucene 6.4.1. (#22978)\n\n",
      "commitDate": 1486369723000,
      "commitName": "c8496fc4f44735962646c1f02572443bf57d3018",
      "commitAuthor": "Adrien Grand",
      "commitDateOld": 1465568292000,
      "commitNameOld": "44c653f5a87337a02daf4737bcb34150df509dbe",
      "commitAuthorOld": "Adrien Grand",
      "daysBetweenCommits": 240.76,
      "commitsBetweenForRepo": 3318,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n     protected void blend(final TermContext[] contexts, int maxDoc, IndexReader reader) throws IOException {\n         if (contexts.length \u003c\u003d 1) {\n             return;\n         }\n         int max \u003d 0;\n         long minSumTTF \u003d Long.MAX_VALUE;\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             TermContext ctx \u003d contexts[i];\n             int df \u003d ctx.docFreq();\n             // we use the max here since it\u0027s the only \"true\" estimation we can make here\n             // at least max(df) documents have that term. Sum or Averages don\u0027t seem\n             // to have a significant meaning here.\n             // TODO: Maybe it could also make sense to assume independent distributions of documents and eg. have:\n             //   df \u003d df1 + df2 - (df1 * df2 / maxDoc)?\n             max \u003d Math.max(df, max);\n             if (minSumTTF !\u003d -1 \u0026\u0026 ctx.totalTermFreq() !\u003d -1) {\n                 // we need to find out the minimum sumTTF to adjust the statistics\n                 // otherwise the statistics don\u0027t match\n                 minSumTTF \u003d Math.min(minSumTTF, reader.getSumTotalTermFreq(terms[i].field()));\n             } else {\n                 minSumTTF \u003d -1;\n             }\n \n         }\n         if (minSumTTF !\u003d -1 \u0026\u0026 maxDoc \u003e minSumTTF) {\n             maxDoc \u003d (int)minSumTTF;\n         }\n \n         if (max \u003d\u003d 0) {\n             return; // we are done that term doesn\u0027t exist at all\n         }\n         long sumTTF \u003d minSumTTF \u003d\u003d -1 ? -1 : 0;\n         final int[] tieBreak \u003d new int[contexts.length];\n         for (int i \u003d 0; i \u003c tieBreak.length; ++i) {\n             tieBreak[i] \u003d i;\n         }\n         new InPlaceMergeSorter() {\n             @Override\n             protected void swap(int i, int j) {\n                 final int tmp \u003d tieBreak[i];\n                 tieBreak[i] \u003d tieBreak[j];\n                 tieBreak[j] \u003d tmp;\n             }\n             @Override\n             protected int compare(int i, int j) {\n                 return Integer.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());\n             }\n         }.sort(0, tieBreak.length);\n         int prev \u003d contexts[tieBreak[0]].docFreq();\n         int actualDf \u003d Math.min(maxDoc, max);\n         assert actualDf \u003e\u003d0 : \"DF must be \u003e\u003d 0\";\n \n \n         // here we try to add a little bias towards\n         // the more popular (more frequent) fields\n         // that acts as a tie breaker\n         for (int i : tieBreak) {\n             TermContext ctx \u003d contexts[i];\n             if (ctx.docFreq() \u003d\u003d 0) {\n                 break;\n             }\n             final int current \u003d ctx.docFreq();\n             if (prev \u003e current) {\n                 actualDf++;\n             }\n-            contexts[i] \u003d ctx \u003d adjustDF(ctx, Math.min(maxDoc, actualDf));\n+            contexts[i] \u003d ctx \u003d adjustDF(reader.getContext(), ctx, Math.min(maxDoc, actualDf));\n             prev \u003d current;\n             if (sumTTF \u003e\u003d 0 \u0026\u0026 ctx.totalTermFreq() \u003e\u003d 0) {\n                 sumTTF +\u003d ctx.totalTermFreq();\n             } else {\n                 sumTTF \u003d -1;  // omit once TF is omitted anywhere!\n             }\n         }\n         sumTTF \u003d Math.min(sumTTF, minSumTTF);\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             int df \u003d contexts[i].docFreq();\n             if (df \u003d\u003d 0) {\n                 continue;\n             }\n             // the blended sumTTF can\u0027t be greater than the sumTTTF on the field\n             final long fixedTTF \u003d sumTTF \u003d\u003d -1 ? -1 : sumTTF;\n-            contexts[i] \u003d adjustTTF(contexts[i], fixedTTF);\n+            contexts[i] \u003d adjustTTF(reader.getContext(), contexts[i], fixedTTF);\n         }\n     }\n\\ No newline at end of file\n"
    },
    "ff4a11aa32b43a1109a364b5d4fed4f8310d0f6c": {
      "type": "Ybodychange",
      "commitMessage": "Replace and ban next batch of Guava classes\n\nThis commit replaces and bans:\n * com.google.common.util.concurrent.UncheckedExecutionException\n * com.google.common.util.concurrent.AtomicLongMap\n * com.google.common.primitives.Longs\n * com.google.common.io.ByteStreams\n * com.google.common.collect.UnmodifiableIterator\n * com.google.common.collect.ObjectArrays\n * com.google.common.collect.Multimap\n * com.google.common.collect.MultimapBuilder\n\nRelates to #13224\n",
      "commitDate": 1442321081000,
      "commitName": "ff4a11aa32b43a1109a364b5d4fed4f8310d0f6c",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": 1441354561000,
      "commitNameOld": "4f5591be8d704868876856a53615ee71c588b07c",
      "commitAuthorOld": "Adrien Grand",
      "daysBetweenCommits": 11.19,
      "commitsBetweenForRepo": 171,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n     protected void blend(final TermContext[] contexts, int maxDoc, IndexReader reader) throws IOException {\n         if (contexts.length \u003c\u003d 1) {\n             return;\n         }\n         int max \u003d 0;\n         long minSumTTF \u003d Long.MAX_VALUE;\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             TermContext ctx \u003d contexts[i];\n             int df \u003d ctx.docFreq();\n             // we use the max here since it\u0027s the only \"true\" estimation we can make here\n             // at least max(df) documents have that term. Sum or Averages don\u0027t seem\n             // to have a significant meaning here.\n             // TODO: Maybe it could also make sense to assume independent distributions of documents and eg. have:\n             //   df \u003d df1 + df2 - (df1 * df2 / maxDoc)?\n             max \u003d Math.max(df, max);\n             if (minSumTTF !\u003d -1 \u0026\u0026 ctx.totalTermFreq() !\u003d -1) {\n                 // we need to find out the minimum sumTTF to adjust the statistics\n                 // otherwise the statistics don\u0027t match\n                 minSumTTF \u003d Math.min(minSumTTF, reader.getSumTotalTermFreq(terms[i].field()));\n             } else {\n                 minSumTTF \u003d -1;\n             }\n \n         }\n         if (minSumTTF !\u003d -1 \u0026\u0026 maxDoc \u003e minSumTTF) {\n             maxDoc \u003d (int)minSumTTF;\n         }\n \n         if (max \u003d\u003d 0) {\n             return; // we are done that term doesn\u0027t exist at all\n         }\n         long sumTTF \u003d minSumTTF \u003d\u003d -1 ? -1 : 0;\n         final int[] tieBreak \u003d new int[contexts.length];\n         for (int i \u003d 0; i \u003c tieBreak.length; ++i) {\n             tieBreak[i] \u003d i;\n         }\n         new InPlaceMergeSorter() {\n             @Override\n             protected void swap(int i, int j) {\n                 final int tmp \u003d tieBreak[i];\n                 tieBreak[i] \u003d tieBreak[j];\n                 tieBreak[j] \u003d tmp;\n             }\n             @Override\n             protected int compare(int i, int j) {\n-                return Ints.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());\n+                return Integer.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());\n             }\n         }.sort(0, tieBreak.length);\n         int prev \u003d contexts[tieBreak[0]].docFreq();\n         int actualDf \u003d Math.min(maxDoc, max);\n         assert actualDf \u003e\u003d0 : \"DF must be \u003e\u003d 0\";\n \n \n         // here we try to add a little bias towards\n         // the more popular (more frequent) fields\n         // that acts as a tie breaker\n         for (int i : tieBreak) {\n             TermContext ctx \u003d contexts[i];\n             if (ctx.docFreq() \u003d\u003d 0) {\n                 break;\n             }\n             final int current \u003d ctx.docFreq();\n             if (prev \u003e current) {\n                 actualDf++;\n             }\n             contexts[i] \u003d ctx \u003d adjustDF(ctx, Math.min(maxDoc, actualDf));\n             prev \u003d current;\n             if (sumTTF \u003e\u003d 0 \u0026\u0026 ctx.totalTermFreq() \u003e\u003d 0) {\n                 sumTTF +\u003d ctx.totalTermFreq();\n             } else {\n                 sumTTF \u003d -1;  // omit once TF is omitted anywhere!\n             }\n         }\n         sumTTF \u003d Math.min(sumTTF, minSumTTF);\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             int df \u003d contexts[i].docFreq();\n             if (df \u003d\u003d 0) {\n                 continue;\n             }\n             // the blended sumTTF can\u0027t be greater than the sumTTTF on the field\n             final long fixedTTF \u003d sumTTF \u003d\u003d -1 ? -1 : sumTTF;\n             contexts[i] \u003d adjustTTF(contexts[i], fixedTTF);\n         }\n     }\n\\ No newline at end of file\n"
    },
    "15a62448343fd24f8e63f43b1e4b16f50005e4a5": {
      "type": "Yfilerename",
      "commitMessage": "create core module\n",
      "commitDate": 1433502723000,
      "commitName": "15a62448343fd24f8e63f43b1e4b16f50005e4a5",
      "commitAuthor": "Simon Willnauer",
      "commitDateOld": 1433502668000,
      "commitNameOld": "7ccc193a666e2ae888e7ac93d677a2143e5e07c3",
      "commitAuthorOld": "Simon Willnauer",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": ""
    },
    "fd416d5ed5d0487964ce13d472fb2f31d456ca3b": {
      "type": "Ybodychange",
      "commitMessage": "Upgrade to Lucene-5.2-snapshot-1674183.\n",
      "commitDate": 1429257930000,
      "commitName": "fd416d5ed5d0487964ce13d472fb2f31d456ca3b",
      "commitAuthor": "Adrien Grand",
      "commitDateOld": 1424729308000,
      "commitNameOld": "0fa5b87fddc10ce487299c10fd3a833962058959",
      "commitAuthorOld": "Robert Muir",
      "daysBetweenCommits": 52.41,
      "commitsBetweenForRepo": 475,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,84 @@\n-    protected void blend(TermContext[] contexts, int maxDoc, IndexReader reader) throws IOException {\n+    protected void blend(final TermContext[] contexts, int maxDoc, IndexReader reader) throws IOException {\n         if (contexts.length \u003c\u003d 1) {\n             return;\n         }\n         int max \u003d 0;\n         long minSumTTF \u003d Long.MAX_VALUE;\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             TermContext ctx \u003d contexts[i];\n             int df \u003d ctx.docFreq();\n             // we use the max here since it\u0027s the only \"true\" estimation we can make here\n             // at least max(df) documents have that term. Sum or Averages don\u0027t seem\n             // to have a significant meaning here.\n             // TODO: Maybe it could also make sense to assume independent distributions of documents and eg. have:\n             //   df \u003d df1 + df2 - (df1 * df2 / maxDoc)?\n             max \u003d Math.max(df, max);\n             if (minSumTTF !\u003d -1 \u0026\u0026 ctx.totalTermFreq() !\u003d -1) {\n                 // we need to find out the minimum sumTTF to adjust the statistics\n                 // otherwise the statistics don\u0027t match\n                 minSumTTF \u003d Math.min(minSumTTF, reader.getSumTotalTermFreq(terms[i].field()));\n             } else {\n                 minSumTTF \u003d -1;\n             }\n \n         }\n         if (minSumTTF !\u003d -1 \u0026\u0026 maxDoc \u003e minSumTTF) {\n             maxDoc \u003d (int)minSumTTF;\n         }\n \n         if (max \u003d\u003d 0) {\n             return; // we are done that term doesn\u0027t exist at all\n         }\n         long sumTTF \u003d minSumTTF \u003d\u003d -1 ? -1 : 0;\n-        final TermContext[] tieBreak \u003d new TermContext[contexts.length];\n-        System.arraycopy(contexts, 0, tieBreak, 0, contexts.length);\n-        ArrayUtil.timSort(tieBreak, new Comparator\u003cTermContext\u003e() {\n+        final int[] tieBreak \u003d new int[contexts.length];\n+        for (int i \u003d 0; i \u003c tieBreak.length; ++i) {\n+            tieBreak[i] \u003d i;\n+        }\n+        new InPlaceMergeSorter() {\n             @Override\n-            public int compare(TermContext o1, TermContext o2) {\n-                return Ints.compare(o2.docFreq(), o1.docFreq());\n+            protected void swap(int i, int j) {\n+                final int tmp \u003d tieBreak[i];\n+                tieBreak[i] \u003d tieBreak[j];\n+                tieBreak[j] \u003d tmp;\n             }\n-        });\n-        int prev \u003d tieBreak[0].docFreq();\n+            @Override\n+            protected int compare(int i, int j) {\n+                return Ints.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());\n+            }\n+        }.sort(0, tieBreak.length);\n+        int prev \u003d contexts[tieBreak[0]].docFreq();\n         int actualDf \u003d Math.min(maxDoc, max);\n         assert actualDf \u003e\u003d0 : \"DF must be \u003e\u003d 0\";\n \n \n         // here we try to add a little bias towards\n         // the more popular (more frequent) fields\n         // that acts as a tie breaker\n-        for (TermContext ctx : tieBreak) {\n+        for (int i : tieBreak) {\n+            TermContext ctx \u003d contexts[i];\n             if (ctx.docFreq() \u003d\u003d 0) {\n                 break;\n             }\n             final int current \u003d ctx.docFreq();\n             if (prev \u003e current) {\n                 actualDf++;\n             }\n-            ctx.setDocFreq(Math.min(maxDoc, actualDf));\n+            contexts[i] \u003d ctx \u003d adjustDF(ctx, Math.min(maxDoc, actualDf));\n             prev \u003d current;\n             if (sumTTF \u003e\u003d 0 \u0026\u0026 ctx.totalTermFreq() \u003e\u003d 0) {\n                 sumTTF +\u003d ctx.totalTermFreq();\n             } else {\n                 sumTTF \u003d -1;  // omit once TF is omitted anywhere!\n             }\n         }\n         sumTTF \u003d Math.min(sumTTF, minSumTTF);\n         for (int i \u003d 0; i \u003c contexts.length; i++) {\n             int df \u003d contexts[i].docFreq();\n             if (df \u003d\u003d 0) {\n                 continue;\n             }\n             // the blended sumTTF can\u0027t be greater than the sumTTTF on the field\n             final long fixedTTF \u003d sumTTF \u003d\u003d -1 ? -1 : sumTTF;\n             contexts[i] \u003d adjustTTF(contexts[i], fixedTTF);\n         }\n     }\n\\ No newline at end of file\n"
    },
    "162ca993762ffb5f720ae7f82adcc209d16a5bd2": {
      "type": "Yintroduced",
      "commitMessage": "Added `cross_fields` mode to multi_match query\n\n`cross_fields` attemps to treat fields with the same analysis\nconfiguration as a single field and uses maximum score promotion or\ncombination of the scores based depending on the `use_dis_max` setting.\nBy default scores are combined. `cross_fields` can also search across\nfields of hetrogenous types for instance if numbers can be part of\nthe query it makes sense to search also on numeric fields if an analyzer\nis provided in the reqeust.\n\nRelates to #2959\n",
      "commitDate": 1391703355000,
      "commitName": "162ca993762ffb5f720ae7f82adcc209d16a5bd2",
      "commitAuthor": "Simon Willnauer"
    }
  }
}