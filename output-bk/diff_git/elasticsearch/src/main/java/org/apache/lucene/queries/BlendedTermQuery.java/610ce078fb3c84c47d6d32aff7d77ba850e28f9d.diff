diff --git a/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java b/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
index 67812771621..50f54731970 100644
--- a/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
+++ b/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
@@ -115,101 +115,101 @@ public abstract class BlendedTermQuery extends Query {
         long sumTTF = minSumTTF == -1 ? -1 : 0;
         final TermContext[] tieBreak = new TermContext[contexts.length];
         System.arraycopy(contexts, 0, tieBreak, 0, contexts.length);
         ArrayUtil.timSort(tieBreak, new Comparator<TermContext>() {
             @Override
             public int compare(TermContext o1, TermContext o2) {
                 return Ints.compare(o2.docFreq(), o1.docFreq());
             }
         });
         int prev = tieBreak[0].docFreq();
         int actualDf = Math.min(maxDoc, max);
         assert actualDf >=0 : "DF must be >= 0";
 
 
         // here we try to add a little bias towards
         // the more popular (more frequent) fields
         // that acts as a tie breaker
         for (TermContext ctx : tieBreak) {
             if (ctx.docFreq() == 0) {
                 break;
             }
             final int current = ctx.docFreq();
             if (prev > current) {
                 actualDf++;
             }
             ctx.setDocFreq(Math.min(maxDoc, actualDf));
             prev = current;
             if (sumTTF >= 0 && ctx.totalTermFreq() >= 0) {
                 sumTTF += ctx.totalTermFreq();
             } else {
                 sumTTF = -1;  // omit once TF is omitted anywhere!
             }
         }
         sumTTF = Math.min(sumTTF, minSumTTF);
         for (int i = 0; i < contexts.length; i++) {
             int df = contexts[i].docFreq();
             if (df == 0) {
                 continue;
             }
             // the blended sumTTF can't be greater than the sumTTTF on the field
             final long fixedTTF = sumTTF == -1 ? -1 : sumTTF;
             contexts[i] = adjustTTF(contexts[i], fixedTTF);
         }
     }
 
     private TermContext adjustTTF(TermContext termContext, long sumTTF) {
         if (sumTTF == -1 && termContext.totalTermFreq() == -1) {
             return termContext;
         }
         TermContext newTermContext = new TermContext(termContext.topReaderContext);
-        List<AtomicReaderContext> leaves = termContext.topReaderContext.leaves();
+        List<LeafReaderContext> leaves = termContext.topReaderContext.leaves();
         final int len;
         if (leaves == null) {
             len = 1;
         } else {
             len = leaves.size();
         }
         int df = termContext.docFreq();
         long ttf = sumTTF;
         for (int i = 0; i < len; i++) {
             TermState termState = termContext.get(i);
             if (termState == null) {
                 continue;
             }
             newTermContext.register(termState, i, df, ttf);
             df = 0;
             ttf = 0;
         }
         return newTermContext;
     }
 
     @Override
     public String toString(String field) {
         return "blended(terms: " + Arrays.toString(terms) + ")";
 
     }
 
     @Override
     public void extractTerms(Set<Term> terms) {
         for (Term term : this.terms) {
             terms.add(term);
         }
     }
 
     private volatile Term[] equalTerms = null;
 
     private Term[] equalsTerms() {
         if (terms.length == 1) {
             return terms;
         }
         if (equalTerms == null) {
             // sort the terms to make sure equals and hashCode are consistent
             // this should be a very small cost and equivalent to a HashSet but less object creation
             final Term[] t = new Term[terms.length];
             System.arraycopy(terms, 0, t, 0, terms.length);
             ArrayUtil.timSort(t);
             equalTerms = t;
         }
         return equalTerms;
 
     }
